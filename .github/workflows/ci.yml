name: 🔍 CI/CD Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]

env:
  PYTHON_VERSION: '3.9'

jobs:
  test:
    name: 🧪 Tests
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11']
        exclude:
          # Reduz combinações para economizar recursos
          - os: macos-latest
            python-version: '3.8'
          - os: macos-latest
            python-version: '3.10'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 rich lxml flake8 aiohttp

    - name: 🔍 Lint with flake8
      run: |
        # Para erros de sintaxe ou nomes indefinidos (críticos)
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Para outros problemas (não críticos)
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --ignore=E501,W293,W291,F401,F841,E402,F541,F811 --statistics

    - name: 🧪 Run unit tests
      run: |
        # Teste módulos principais
        python -c "import manw_ng.core.scraper; print('Core modules import OK')"
        python -c "from manw_ng.ml import enhanced_ml_classifier, HAS_ENHANCED; print(f'Enhanced ML: {HAS_ENHANCED}')"
        python -c "from manw_ng.ml.enhanced_classifier import enhanced_ml_classifier; stats = enhanced_ml_classifier.get_model_stats(); print(f'Function mappings: {stats[\"mapped_functions\"]:,}')"
        python manw-ng.py --help > help_output.txt && echo "CLI working OK"

    # Note: Coverage disabled temporarily - can be re-enabled later with proper test setup

  integration-tests:
    name: 🌐 Integration Tests
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 rich lxml flake8 aiohttp

    - name: 🎯 Test Standard Win32 APIs
      run: |
        # Testa APIs Win32 padrão
        python manw-ng.py CreateFileW -l us --output json > test_createfile.json
        python -c "import json; data=json.load(open('test_createfile.json')); assert data['return_description'], 'Missing return description'"
        echo "✅ Standard Win32 API test passed"

    - name: 🎯 Test Native APIs
      run: |
        # Testa Native APIs (NTAPI)
        python manw-ng.py NtCreateFile -l us --output json > test_native.json
        python -c "import json; data=json.load(open('test_native.json')); assert data['return_description'], 'Missing return description'"
        echo "✅ Native API test passed"

    - name: 🎯 Test Shell APIs
      run: |
        # Testa Shell APIs
        python manw-ng.py PathCombineW -l us --output json > test_shell.json
        python -c "import json; data=json.load(open('test_shell.json')); assert data['return_description'], 'Missing return description'"
        echo "✅ Shell API test passed"

    - name: 🎯 Test Enhanced ML Coverage
      run: |
        # Testa cobertura do sistema ML melhorado
        python -c "
        from manw_ng.ml.enhanced_classifier import enhanced_ml_classifier
        import random
        
        # Testa várias categorias de funções
        test_functions = [
            'CreateProcessW', 'RegOpenKeyExW', 'NtCreateFile', 'ZwAllocateVirtualMemory',
            'PathCombineW', 'SHGetFolderPathW', 'PlaySoundW', 'waveOutOpen',
            'CryptAcquireContextW', 'WSAStartup', 'InternetOpenW', 'glBegin'
        ]
        
        predictions_made = 0
        high_confidence = 0
        
        for func in test_functions:
            predictions = enhanced_ml_classifier.predict_headers(func, top_k=1)
            if predictions:
                predictions_made += 1
                if predictions[0][1] > 0.8:
                    high_confidence += 1
                print(f'{func}: {predictions[0][0]} ({predictions[0][1]:.2f})')
        
        coverage = predictions_made / len(test_functions) * 100
        confidence_rate = high_confidence / predictions_made * 100 if predictions_made > 0 else 0
        
        print(f'Coverage: {coverage:.1f}% ({predictions_made}/{len(test_functions)})')
        print(f'High Confidence: {confidence_rate:.1f}% ({high_confidence}/{predictions_made})')
        
        assert coverage >= 95, f'Coverage too low: {coverage}%'
        assert confidence_rate >= 90, f'Confidence rate too low: {confidence_rate}%'
        "
        echo "✅ Enhanced ML system test passed"

  security:
    name: 🔒 Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install bandit[toml] safety

    - name: 🔍 Run Bandit security scan
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . || true

    - name: 🛡️ Check dependencies for vulnerabilities
      run: |
        safety check --json --output safety-report.json || true
        safety check || true

    - name: 📊 Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  code-quality:
    name: 📝 Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 rich lxml flake8 black mypy

    - name: 🎨 Check code formatting with Black
      run: |
        black --check --diff .

    - name: 📝 Type checking with MyPy
      run: |
        mypy manw-ng.py --ignore-missing-imports || true

    - name: 📊 Generate complexity report
      run: |
        flake8 . --exit-zero --statistics > flake8-report.txt
      
    - name: 📊 Upload code quality reports
      uses: actions/upload-artifact@v4
      with:
        name: code-quality-reports
        path: flake8-report.txt

  performance:
    name: ⚡ Performance Tests
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 🐍 Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 rich lxml flake8 pytest-benchmark aiohttp

    - name: ⚡ Run performance benchmarks
      run: |
        # Testa performance do sistema ML aprimorado
        python -c "
        import time
        from manw_ng.ml.enhanced_classifier import enhanced_ml_classifier
        
        # Testa velocidade de predição
        test_functions = ['CreateFileW', 'RegOpenKeyW', 'NtCreateFile', 'PathCombineW', 'WSAStartup'] * 20
        
        start = time.time()
        for func in test_functions:
            predictions = enhanced_ml_classifier.predict_headers(func, top_k=1)
        end = time.time()
        
        total_predictions = len(test_functions)
        elapsed = end - start
        rate = total_predictions / elapsed
        
        print(f'ML Predictions: {total_predictions} in {elapsed:.3f}s')
        print(f'Prediction Rate: {rate:.0f} predictions/second')
        
        # Sistema deve ser rápido (>1000 predições/segundo)
        assert rate > 1000, f'Performance too slow: {rate:.0f} predictions/second'
        
        # Testa estatísticas do sistema
        stats = enhanced_ml_classifier.get_model_stats()
        print(f'System Stats: {stats[\"mapped_headers\"]} headers, {stats[\"mapped_functions\"]:,} mappings')
        assert stats['mapped_functions'] > 50000, 'Function mapping count too low'
        "
        echo "✅ Performance benchmarks passed"

  deploy-docs:
    name: 📚 Deploy Documentation
    runs-on: ubuntu-latest
    needs: [test, integration-tests, security, code-quality]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4

    - name: 📚 Generate documentation badge
      run: |
        # Cria badge de documentação
        echo "![Documentation](https://img.shields.io/badge/docs-latest-brightgreen.svg)" > docs-badge.md

    - name: 📊 Update README with test results
      run: |
        # Poderia atualizar README com resultados dos testes
        echo "Tests completed successfully at $(date)" >> test-results.md

  notify:
    name: 📢 Notifications
    runs-on: ubuntu-latest
    needs: [test, integration-tests, security, code-quality, performance]
    if: always()
    
    steps:
    - name: 📢 Notify on success
      if: needs.test.result == 'success' && needs.integration-tests.result == 'success'
      run: |
        echo "✅ All tests passed successfully!"
        echo "📊 Coverage report generated"
        echo "🔒 Security scan completed"
        echo "📝 Code quality checks passed"

    - name: 📢 Notify on failure
      if: needs.test.result == 'failure' || needs.integration-tests.result == 'failure'
      run: |
        echo "❌ Tests failed!"
        echo "Please check the logs for details."
        exit 1